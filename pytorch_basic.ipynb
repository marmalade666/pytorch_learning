{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pytorch 中文文档：\n",
    "https://pytorch-cn.readthedocs.io/zh/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 安装pytorch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://zhuanlan.zhihu.com/p/76901725"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "安装CPU版本 https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度学习经典流程"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "深度学习经典数据处理流程：\n",
    "1.加载数据和标签（如手写数字识别中的数据就是一张图片，而一张图片在计算机里面是一个由整数组成的矩阵，它的标签是当前这个图片到底是数字几）\n",
    "2.设计网络结构（如是共有几层神经网络，每层输入输出的矩阵格式，每层的激活函数是怎样的，当前层到底是卷积层还是循环神经网络层等等）\n",
    "3.设计损失（误差）函数（以手写数字识别为例，神经网络会输出一个值表明当前这个图片到底是几，但是一开始肯定不准确。\n",
    "  所以我们需要计算神经网络输出值与标签之间的误差。误差计算有很多种，需要告诉pytorch怎么计算误差。\n",
    "    然后pytorch就会自动根据我们设定的误差计算方法去自动调整神经网络的参数）\n",
    "4.设置用于自动调整神经网络参数的优化器（在上一步我们提到了pytorch会自动帮我们自动调整神经网络的参数，但是具体用哪种优化器去调整参数呢？\n",
    "  这需要我们告诉pytorch，用代码设置具体用哪个优化器调整参数）\n",
    "5.使用数据和标签训练神经网络\n",
    "6.这个神经网络已经训练好可以用于解决你的问题了。（你只用输入数据，然后用神经网络输出结果即可）\n",
    "总结：\n",
    "1.载入训练集和测试集\n",
    "2.设计网络结构\n",
    "3.设计损失函数\n",
    "4.确定优化器\n",
    "5.训练模型\n",
    "6.应用模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上面流程的伪代码\n",
    "import torch\n",
    "# 1. 加载数据和标签\n",
    "data,label = 加载数据()\n",
    "# 2. 设计网络结构\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(第1层输入向量维数, 第1层输出的向量维数), # 输入向量维数其实就是当前这层的“神经元”的个数，输出向量维数和下一层输入向量维数要一样\n",
    "    torch.nn.ReLU(), # 设置前面那一层的激活函数\n",
    "    ....\n",
    "    torch.nn.Linear(第n层输入向量维数, 第n层输出向量维数),\n",
    "    torch.nn.ReLU(), # 设置前面那一层的激活函数\n",
    ")\n",
    "# 3. 设计损失函数，就是最简单的两点间距离(model_output-lable)^2\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "# 4. 设置用于自动调节神经网络参数的优化器\n",
    "learning_rate = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# 5. 训练神经网络（重复训练10次）\n",
    "for t in range(10):\n",
    "    model_output = model(data)\n",
    "    # 5.1 用所设计算损失(误差)函数计算误差\n",
    "    loss = loss_fn(model_output, label)\n",
    "    # 5.2 每次训练前清零之前计算的梯度(导数)\n",
    "    optimizer.zero_grad()\n",
    "    # 5.3 根据误差反向传播计算误差对各个权重的导数\n",
    "    loss.backward()\n",
    "    # 5.4 根据优化器里面的算法自动调整神经网络权重\n",
    "    optimizer.step()\n",
    "\n",
    "##########现在你已经训练好了#################\n",
    "# 6. 用这个神经网络解决你的问题，比如手写数字识别，输入一个图片矩阵，然后模型返回一个数字\n",
    "result_digit = model(img_mattrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 理解 Tensor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.1  Tensor\n",
    "Tensor是PyTorch中重要的数据结构，可认为是一个高维数组。\n",
    "它可以是一个数（标量）、一维数组（向量）、二维数组（矩阵）以及更高维的数组。\n",
    "Tensor和Numpy的ndarrays类似，但Tensor可以使用GPU进行加速。\n",
    "Tensor的使用和Numpy及Matlab的接口十分相似？？，下面通过几个例子来看看Tensor的基本使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch as t\n",
    "t.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 5x3 矩阵，只是分配了空间，未初始化\n",
    "x = t.Tensor(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9044, 0.6508, 0.3733],\n",
       "        [0.1609, 0.0863, 0.9537],\n",
       "        [0.6969, 0.4444, 0.1294],\n",
       "        [0.1012, 0.3715, 0.7128],\n",
       "        [0.9223, 0.8155, 0.0151]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用[0,1]均匀分布随机初始化二维数组\n",
    "x = t.rand(5, 3)  \n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自定义二维数组\n",
    "x = t.Tensor([[1,2],[3,4]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x.size()) # 查看x的形状\n",
    "x.size()[1], x.size(1) # 查看列的个数, 两种写法等价"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.Size 是tuple对象的子类，因此它支持tuple的所有操作，如x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9967, 1.3346, 1.1809],\n",
       "        [0.2247, 1.0827, 1.0660],\n",
       "        [1.6908, 1.1105, 0.3317],\n",
       "        [0.9556, 0.7512, 0.7482],\n",
       "        [1.5752, 0.8984, 0.6632]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = t.rand(5, 3)\n",
    "# 加法的第一种写法\n",
    "x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9967, 1.3346, 1.1809],\n",
       "        [0.2247, 1.0827, 1.0660],\n",
       "        [1.6908, 1.1105, 0.3317],\n",
       "        [0.9556, 0.7512, 0.7482],\n",
       "        [1.5752, 0.8984, 0.6632]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的第二种写法\n",
    "t.add(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9967, 1.3346, 1.1809],\n",
       "        [0.2247, 1.0827, 1.0660],\n",
       "        [1.6908, 1.1105, 0.3317],\n",
       "        [0.9556, 0.7512, 0.7482],\n",
       "        [1.5752, 0.8984, 0.6632]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加法的第三种写法：指定加法结果的输出目标为result\n",
    "result = t.Tensor(5, 3) # 预先分配空间\n",
    "t.add(x, y, out=result) # 输入到result\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最初y\n",
      "tensor([[0.0923, 0.6838, 0.8076],\n",
      "        [0.0638, 0.9964, 0.1123],\n",
      "        [0.9939, 0.6661, 0.2022],\n",
      "        [0.8544, 0.3796, 0.0353],\n",
      "        [0.6529, 0.0829, 0.6481]])\n",
      "第一种加法，y的结果\n",
      "tensor([[0.0923, 0.6838, 0.8076],\n",
      "        [0.0638, 0.9964, 0.1123],\n",
      "        [0.9939, 0.6661, 0.2022],\n",
      "        [0.8544, 0.3796, 0.0353],\n",
      "        [0.6529, 0.0829, 0.6481]])\n",
      "第二种加法，y的结果\n",
      "tensor([[0.9967, 1.3346, 1.1809],\n",
      "        [0.2247, 1.0827, 1.0660],\n",
      "        [1.6908, 1.1105, 0.3317],\n",
      "        [0.9556, 0.7512, 0.7482],\n",
      "        [1.5752, 0.8984, 0.6632]])\n"
     ]
    }
   ],
   "source": [
    "print('最初y')\n",
    "print(y)\n",
    "\n",
    "print('第一种加法，y的结果')\n",
    "y.add(x) # 普通加法，不改变y的内容\n",
    "print(y)\n",
    "\n",
    "print('第二种加法，y的结果')\n",
    "y.add_(x) # inplace 加法，y变了\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "注意，函数名后面带下划线_ 的函数会修改Tensor本身。\n",
    "例如，x.add_(y)和x.t_()会改变 x，\n",
    "但x.add(y)和x.t()返回一个新的Tensor， 而x不变。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6508, 0.0863, 0.4444, 0.3715, 0.8155])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor的选取操作与Numpy类似\n",
    "x[:, 1]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tensor还支持很多操作，包括数学运算、线性代数、选择、切片等等，\n",
    "其接口设计与Numpy极为相似。更详细的使用方法，会在第三章系统讲解。\n",
    "\n",
    "Tensor和Numpy的数组之间的 互操作 非常容易且快速。\n",
    "对于Tensor不支持的操作，可以先转为Numpy数组处理，之后再转回Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(5) # 新建一个全1的Tensor\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy() # Tensor -> Numpy\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = t.from_numpy(a) # Numpy->Tensor\n",
    "print(a)\n",
    "print(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Tensor和numpy对象共享内存，所以他们之间的转换很快，而且几乎不会消耗什么资源。但这也意味着，如果其中一个变了，另外一个也会随之改变??\n",
    "b.add_(1) # 以`_`结尾的函数会修改自身\n",
    "print(a) #b = t.from_numpy(a) # Numpy->Tensor,所以b变了，对应的a也变了\n",
    "print(b) # Tensor和Numpy共享内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2., dtype=torch.float64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#如果你想获取某一个元素的值，可以使用scalar.item。 \n",
    "#直接tensor[idx]得到的还是一个tensor: 一个0-dim 的tensor，一般称为scalar.\n",
    "scalar = b[0]\n",
    "scalar#一个0-dim 的tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.size() #0-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.item() # 使用scalar.item()能从中取出python对象的数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2]), tensor(2., dtype=torch.float64))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = t.tensor([2]) # 注意和scalar的区别\n",
    "tensor,scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1]), torch.Size([]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.size(),scalar.size() #1-dim 和 0-dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 只有一个元素的tensor也可以调用`tensor.item()`\n",
    "tensor.item(), scalar.item()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "此外在pytorch中还有一个和np.array 很类似的接口: torch.tensor, 二者的使用十分类似。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 4],\n",
       "         [1, 2]]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor4 = t.tensor([[3,4],[1,2]]) # 新建一个包含 3，4 两个元素的tensor\n",
    "tensor4,tensor4.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 4]), torch.Size([2]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = t.tensor([3,4]) # 新建一个包含 3，4 两个元素的tensor\n",
    "tensor,tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3],\n",
       "         [4]]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3 = t.tensor([[3],[4]]) # 新建一个包含 3，4 两个元素的tensor\n",
    "tensor3,tensor3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3]), torch.Size([1]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2 = t.tensor([3]) # 新建一个包含 3，4 两个元素的tensor\n",
    "tensor2,tensor2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3), torch.Size([]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar = t.tensor(3)\n",
    "scalar,scalar.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([3, 4]), tensor([1111,    4]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tensor = tensor\n",
    "new_tensor = t.tensor(old_tensor)\n",
    "new_tensor[0] = 1111\n",
    "old_tensor, new_tensor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "需要注意的是，t.tensor()总是会进行数据拷贝，\n",
    "新tensor和原来的数据不再共享内存。\n",
    "所以如果你想共享内存的话，建议使用torch.from_numpy()或者tensor.detach()来新建一个tensor, 二者共享内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1111,    4]), tensor([1111,    4]))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tensor = old_tensor.detach() #使new_tensor 和 old_tensor指向同一块内存\n",
    "new_tensor[0] = 1111\n",
    "old_tensor, new_tensor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Tensor可通过.cuda 方法转为GPU的Tensor，从而享受GPU带来的加速运算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在不支持CUDA的机器下，下一步还是在CPU上运行\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "z = x+y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch的autograd模块: 自动微分"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "深度学习的算法本质上是通过反向传播求导数，而PyTorch的autograd模块则实现了此功能。\n",
    "在Tensor上的所有操作，autograd 都能为它们 自动提供微分。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "autograd.Variable 是Autograd中的 核心类，它简单封装了Tensor，并支持几乎所有Tensor有的操作。\n",
    "Tensor在被封装为Variable之后，可以调用它的.backward实现反向传播，自动计算所有梯度。\n",
    "\n",
    "从0.4起, Variable 正式合并入Tensor, Variable 本来实现的自动微分功能，Tensor就能支持。\n",
    "读者还是可以使用Variable(tensor), 但是这个操作其实什么都没做。建议读者以后直接使用tensor.\n",
    "\n",
    "要想使得Tensor使用autograd功能，只需要设置tensor.requries_grad=True\n",
    "\n",
    "Variable主要包含三个属性。 - data：保存Variable所包含的Tensor \n",
    "                        - grad：保存data对应的梯度，grad也是个Variable，而不是Tensor，它和data的形状一样。 \n",
    "                        - grad_fn：指向一个Function对象，这个Function用来反向传播计算输入的梯度，具体细节会在下一章讲解。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 为tensor设置 requires_grad 标识，代表着需要求导数\n",
    "# pytorch 会自动调用autograd 记录操作\n",
    "x = t.ones(2, 2, requires_grad=True)\n",
    "# 上一步等价于\n",
    "# x = t.ones(2,2)\n",
    "# x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y# pytorch 会自动调用autograd 记录操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SumBackward0 at 0x1bb975d45c0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn# pytorch 会自动调用autograd 记录操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() # 反向传播,计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y = x.sum() = (x[0][0] + x[0][1] + x[1][0] + x[1][1])\n",
    "# 每个值的梯度都为1\n",
    "x.grad # .grad 记录梯度"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "注意：grad在反向传播过程中是累加的(accumulated)，\n",
    "    这意味着每一次运行反向传播，梯度都会累加之前的梯度，\n",
    "    所以反向传播之前需把梯度清零！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#反向传播之前需把梯度清零！！！\n",
    "# 以下划线结束的函数是inplace操作，会修改自身的值，就像add_\n",
    "x.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Autograd实现了反向传播功能，但是直接用来写深度学习的代码在很多情况下还是稍显复杂，\n",
    "torch.nn是专门为神经网络设计的模块化接口。\n",
    "nn构建于 Autograd之上，可用来定义和运行神经网络。\n",
    "nn.Module是nn中最重要的类，可把它看成是一个网络的封装，包含网络各层定义以及forward方法，调用forward(input)方法，可返回前向传播的结果。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "下面就以最早的卷积神经网络：LeNet为例，来看看如何用nn.Module实现。\n",
    "这是一个基础的前向传播(feed-forward)网络: 接收输入，经过层层传递运算，得到输出。\n",
    "1.定义网络\n",
    "定义网络时，需要 继承 nn.Module，并 实现 它的forward方法，把网络中具有 可学习参数的层 放在 构造函数__init__中。\n",
    "如果某一层(如ReLU)不具有可学习的参数，则既可以放在构造函数中，也可以不放，但建议不放在其中，而在forward中使用nn.functional代替"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module): #继承 nn.Module\n",
    "    def __init__(self): #构造函数：把网络中具有 可学习参数的层 放在 构造函数中\n",
    "        # nn.Module子类的函数必须在构造函数中执行父类的构造函数\n",
    "        \n",
    "        super(Net, self).__init__()# 等价于nn.Module.__init__(self)\n",
    "        \n",
    "        # 卷积层 '1'表示输入图片为单通道, '6'表示输出通道数，'5'表示卷积核为5*5\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) \n",
    "        # 卷积层\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5) \n",
    "        # 仿射层/全连接层，y = Wx + b\n",
    "        self.fc1   = nn.Linear(16*5*5, 120) \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):  #实现 nn.Module的forward方法，前向传播的计算过程\n",
    "        # 卷积 -> 激活 -> 池化 \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        # reshape，‘-1’表示自适应\n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net() #实例化\n",
    "print(net) #打印 网络结构"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "只要在nn.Module的子类中定义了forward函数，backward函数就会自动被实现(利用autograd)。\n",
    "在forward 函数中可使用任何tensor支持的函数，还可以使用if、for循环、print、log等Python语法，写法和标准的Python写法一致。\n",
    "\n",
    "网络的可学习参数通过net.parameters()返回，\n",
    "net.named_parameters可同时返回可学习的参数及名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight : torch.Size([6, 1, 5, 5])\n",
      "conv1.bias : torch.Size([6])\n",
      "conv2.weight : torch.Size([16, 6, 5, 5])\n",
      "conv2.bias : torch.Size([16])\n",
      "fc1.weight : torch.Size([120, 400])\n",
      "fc1.bias : torch.Size([120])\n",
      "fc2.weight : torch.Size([84, 120])\n",
      "fc2.bias : torch.Size([84])\n",
      "fc3.weight : torch.Size([10, 84])\n",
      "fc3.bias : torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name,parameters in net.named_parameters():\n",
    "    print(name,':',parameters.size())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "forward函数的输入和输出都是Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-2.4157,  0.3548,  1.1107,  ...,  1.4344,  0.4507,  1.7374],\n",
      "          [ 0.2202, -1.6681, -0.3863,  ..., -0.1833, -0.4232, -0.5931],\n",
      "          [-0.5320, -0.7660,  0.1837,  ..., -0.0760,  0.1146,  0.5582],\n",
      "          ...,\n",
      "          [ 0.1752,  0.1834, -0.1811,  ...,  0.0694,  0.1028,  0.9293],\n",
      "          [-0.1299, -1.8872, -1.3495,  ..., -0.1046,  1.0326,  0.3368],\n",
      "          [-0.7864, -1.2458,  2.7532,  ...,  0.6215, -0.3607,  0.0608]]]])\n",
      "torch.Size([1, 1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = t.randn(1, 1, 32, 32) #𝑛𝑆𝑎𝑚𝑝𝑙𝑒𝑠=1，𝑛𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝑠=1，𝐻𝑒𝑖𝑔ℎ𝑡=32，𝑊𝑖𝑑𝑡ℎ=32\n",
    "print(input)\n",
    "print(input.size())\n",
    "out = net(input) #正向传播\n",
    "out.size() #10个手写数字，10个类别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad() # 所有参数的梯度清零\n",
    "out.backward(t.ones(1,10)) # 反向传播\n",
    "#t.ones(1,10) 干啥的？"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "需要注意的是，torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。\n",
    "但如果只想输入一个样本，则用 input.unsqueeze(0)将batch_size设为１。\n",
    "例如 nn.Conv2d 输入必须是4维的，形如𝑛𝑆𝑎𝑚𝑝𝑙𝑒𝑠×𝑛𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝑠×𝐻𝑒𝑖𝑔ℎ𝑡×𝑊𝑖𝑑𝑡ℎ。可将nSample设为1，即1×𝑛𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝑠×𝐻𝑒𝑖𝑔ℎ𝑡×𝑊𝑖𝑑𝑡ℎ。\n",
    "所以input = t.randn(1, 1, 32, 32)含义是 𝑛𝑆𝑎𝑚𝑝𝑙𝑒𝑠=1，𝑛𝐶ℎ𝑎𝑛𝑛𝑒𝑙𝑠=1，𝐻𝑒𝑖𝑔ℎ𝑡=32，𝑊𝑖𝑑𝑡ℎ=32 ？??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 损失函数"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import torch.nn as nn 实现了神经网络中大多数的损失函数，\n",
    "例如 nn.MSELoss用来计算 均方误差，\n",
    "nn.CrossEntropyLoss用来计算 交叉熵损失。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28.4415, grad_fn=<MseLossBackward>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input) #定义 output 的结构\n",
    "target = t.arange(0,10).view(1,10)  #目标输出\n",
    "target = target.float()\n",
    "criterion = nn.MSELoss() #定义 损失函数\n",
    "loss = criterion(output, target) #应用损失函数\n",
    "loss # loss是个scalar"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "如果对loss进行反向传播溯源(使用`gradfn`属性)，可看到它的计算图如下：\n",
    "\n",
    "```\n",
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d  \n",
    "      -> view -> linear -> relu -> linear -> relu -> linear \n",
    "      -> MSELoss\n",
    "      -> loss\n",
    "```\n",
    "\n",
    "当调用`loss.backward()`时，该图会动态生成并自动微分，也即会自动计算图中参数(Parameter)的导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "反向传播之前 conv1.bias的梯度\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "反向传播之后 conv1.bias的梯度\n",
      "tensor([ 0.0597, -0.0370,  0.0100, -0.0031, -0.0355, -0.0475])\n"
     ]
    }
   ],
   "source": [
    "# 运行.backward，观察调用之前和调用之后的grad\n",
    "net.zero_grad() # 把net中所有可学习参数的梯度清零\n",
    "print('反向传播之前 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)\n",
    "loss.backward()\n",
    "print('反向传播之后 conv1.bias的梯度')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 优化器"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# 在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法(SGD)的更新策略如下：\n",
    "\n",
    "weight = weight - learning_rate * gradient\n",
    "手动实现如下：\n",
    "\n",
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)# inplace 减法"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torch.optim 中实现了深度学习中绝大多数的优化方法，\n",
    "例如RMSProp、Adam、SGD等，更便于使用，因此大多数时候并不需要手动写上述代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "#新建一个优化器，指定要调整的参数和学习率\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.01)\n",
    "\n",
    "# 在训练过程中\n",
    "# 先梯度清零(与net.zero_grad()效果一样)\n",
    "optimizer.zero_grad() \n",
    "\n",
    "# 计算损失\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "\n",
    "#反向传播\n",
    "loss.backward()\n",
    "\n",
    "#更新参数\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据加载与预处理"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "在深度学习中数据加载及预处理是非常复杂繁琐的，但PyTorch提供了一些可极大简化和加快数据处理流程的工具。\n",
    "对于常用的数据集，PyTorch也提供了封装好的接口供用户快速调用，这些数据集主要保存在torchvison中。\n",
    "\n",
    "torchvision实现了常用的图像数据加载功能，例如Imagenet、CIFAR10、MNIST等，\n",
    "以及常用的数据转换操作，这极大地方便了数据加载，并且代码具有可重用性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小试牛刀：CIFAR-10分类"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "步骤如下:\n",
    "1.使用 torchvision加载并预处理CIFAR-10数据集\n",
    "2.定义网络\n",
    "3.定义损失函数和优化器\n",
    "4.训练网络并更新网络参数\n",
    "5.测试网络"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "CIFAR-10数据加载及预处理\n",
    "CIFAR-10^3是一个常用的彩色图片数据集，\n",
    "它有10个类别: 'airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'。\n",
    "每张图片都是3×32×32，也即3-通道彩色图片，分辨率为32×32。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToPILImage\n",
    "show = ToPILImage() # 可以把Tensor转成Image，方便可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchvision"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " ##https://cloud.tencent.com/developer/article/1384520\n",
    " PyTorch框架中有一个很常用的包：torchvision\n",
    " torchvision主要由3个子包构成：torchvision.datasets、torchvision.models、torchvision.transforms\n",
    " ##详细内容可参考：http://pytorch.org/docs/master/torchvision/index.html\n",
    " GitHub：https://github.com/pytorch/vision/tree/master/torchvision。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "torchvision.transformas，基本上PyTorch中的resize、crop、normalize等常见的数据预处理及数据增强（data augmentation）操作都可以通过该接口实现。\n",
    "torchvision.transformas主要涉及两个文件：transformas.py和functional.py，在transformas.py中定义了各种data augmentation的类，在每个类中通过调用functional.py中对应的函数完成data augmentation操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一次运行程序torchvision会自动下载CIFAR-10数据集，\n",
    "# 大约100M，需花费一定的时间，\n",
    "# 如果已经下载有CIFAR-10，可通过root参数指定\n",
    "\n",
    "# 定义对数据的预处理\n",
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(), # 转为Tensor\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # 归一化，具体含义是？？\n",
    "                             ])\n",
    "#class torchvision.transforms.Compose(transforms) 将多个transform组合起来使用。\n",
    "#对Tensor进行变换 class torchvision.transforms.Normalize(mean, std) 给定 1均值：(R,G,B) 2方差：（R，G，B），将会把Tensor正则化。即：Normalized_image=(image-mean)/std。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/qq_37385726/article/details/81771980\n",
    "# 1.torchvision.transforms.ToTensor() #将PILImage或者numpy的ndarray转化成Tensor\n",
    "\n",
    "对于PILImage转化的Tensor，其数据类型是torch.FloatTensor\n",
    "对于ndarray的数据类型没有限制，但转化成的Tensor的数据类型是由ndarray的数据类型决定的。\n",
    "\n",
    "2.torchvision.transforms.ToPILImage()\n",
    "将Numpy的ndarray或者Tensor转化成PILImage类型【在数据类型上，两者都有明确的要求】\n",
    "\n",
    "ndarray的数据类型要求dtype=uint8, range[0, 255] and shape H x W x C\n",
    "Tensor 的shape为 C x H x W 要求是FloadTensor的，不允许DoubleTensor或者其他类型\n",
    "                # to a PIL.Image of range [0, 255]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把一个取值范围是[0,255]的PIL.Image 转换成 Tensor\n",
    "img1 = Image.open('./Image/use_Crop.jpg')\n",
    " \n",
    "t_out = transforms.ToTensor()(img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape为(H,W,C)的numpy.ndarray，转换成形状为[C,H,W]，取值范围是[0,1.0]的Tensor??\n",
    "n_out = np.random.rand(100,100,3)\n",
    "print(n_out.dtype)\n",
    " \n",
    "t_out = transforms.ToTensor()(n_out)\n",
    "print(t_out.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将ndarray转化成PILImage\n",
    "#初始化随机数种子\n",
    "np.random.seed(0)\n",
    " \n",
    "data = np.random.randint(0, 255, 300)\n",
    "print(data.dtype)\n",
    "n_out = data.reshape(10,10,3)\n",
    " \n",
    "#强制类型转换\n",
    "n_out = n_out.astype(np.uint8)\n",
    "print(n_out.dtype)\n",
    " \n",
    "img2 = transforms.ToPILImage()(n_out)\n",
    "img2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将Tensor转化成PILImage\n",
    "t_out = torch.randn(3,10,10)\n",
    "img1 = transforms.ToPILImage()(t_out)\n",
    "img1.show()\n",
    "#因为要求是FloatTensor类型，所以最好是不管此时的tensor是不是FloatTensor类型，都加一个强制转换再传进去。 \n",
    "t_out = torch.randn(3,10,10)\n",
    "img1 = transforms.ToPILImage()(t_out.float())\n",
    "img1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#综合处理，ndarray->Tensor->PILImage\n",
    "n_out = np.random.rand(100,100,3)\n",
    "t_out = transforms.ToTensor()(n_out)\n",
    "img2 = transforms.ToPILImage()(t_out.float())  #强制类型转换\n",
    "img2.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "深入理解Ptorchvision.transforms.ToTensor与ToPILImage\n",
    "https://blog.csdn.net/qq_37385726/article/details/81811466"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transforms.Normalize"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Normalize()数据归一化处理，调用前数据需处理成Tensor。\n",
    "对Tensor进行变换 class torchvision.transforms.Normalize(mean, std) \n",
    "给定 1均值mean：(R,G,B) 2方差std：（R，G，B），将会把Tensor正则化。即：Normalized_image=(image-mean)/std。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /home/cy/tmp/data/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████▉| 170418176/170498071 [01:14<00:00, 2609633.66it/s]"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "trainset = tv.datasets.CIFAR10(\n",
    "                    root='/home/cy/tmp/data/', \n",
    "                    train=True, \n",
    "                    download=True,\n",
    "                    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "testset = tv.datasets.CIFAR10(\n",
    "                    '/home/cy/tmp/data/',\n",
    "                    train=False, \n",
    "                    download=True, \n",
    "                    transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainloader = t.utils.data.DataLoader(\n",
    "                    trainset, \n",
    "                    batch_size=4,\n",
    "                    shuffle=True, \n",
    "                    num_workers=2)\n",
    "testloader = t.utils.data.DataLoader(\n",
    "                    testset,\n",
    "                    batch_size=4, \n",
    "                    shuffle=False,\n",
    "                    num_workers=2)\n",
    "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Dataset(tv.datasets)对象是一个数据集，可以按下标访问，返回形如(data, label)的数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ship\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=100x100 at 0x1BB97D42F98>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data, label) = trainset[100]\n",
    "print(classes[label]) #???\n",
    "\n",
    "# (data + 1) / 2是为了还原被归一化的数据\n",
    "show((data + 1) / 2).resize((100, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trainloader = t.utils.data.DataLoader()\n",
    "Dataloader是一个可迭代的对象，它\n",
    "将dataset返回的每一条数据拼接成一个batch，并提供多线程加速优化和数据打乱等操作。\n",
    "当程序对dataset的所有数据遍历完一遍之后，相应的对Dataloader也完成了一次迭代。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       bird         car         dog       horse\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=400x100 at 0x1BB980BCB70>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(trainloader) #batch_size=4\n",
    "images, labels = dataiter.next() # 返回4张图片及标签\n",
    "print(' '.join('%11s'%classes[labels[j]] for j in range(4)))\n",
    "show(tv.utils.make_grid((images+1)/2)).resize((400,100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 定义网络"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "拷贝上面的LeNet网络，修改self.conv1第一个参数为3通道，因CIFAR-10是3通道彩图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5) \n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)  \n",
    "        self.fc1   = nn.Linear(16*5*5, 120)  \n",
    "        self.fc2   = nn.Linear(120, 84)\n",
    "        self.fc3   = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x): \n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2)) \n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2) \n",
    "        x = x.view(x.size()[0], -1) \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#定义损失函数和优化器(loss和optimizer)\n",
    "from torch import optim\n",
    "criterion = nn.CrossEntropyLoss() # 交叉熵损失函数\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) # momentum=0.9？？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## 训练网络\n",
    "所有网络的训练流程都是类似的，不断地执行如下流程：输入数据，前向传播+反向传播，更新参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.140\n",
      "[1,  4000] loss: 1.801\n",
      "[1,  6000] loss: 1.631\n",
      "[1,  8000] loss: 1.549\n",
      "[1, 10000] loss: 1.503\n",
      "[1, 12000] loss: 1.441\n",
      "[2,  2000] loss: 1.395\n",
      "[2,  4000] loss: 1.340\n",
      "[2,  6000] loss: 1.357\n",
      "[2,  8000] loss: 1.304\n",
      "[2, 10000] loss: 1.292\n",
      "[2, 12000] loss: 1.282\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "t.set_num_threads(8) #num_threads 为8，线程数？\n",
    "for epoch in range(2):  #共训练2个epoch\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0): #??? i从0开始的意思？\n",
    "        \n",
    "        # 输入数据\n",
    "        inputs, labels = data #一次迭代 batch_size为4\n",
    "        \n",
    "        # 梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels) \n",
    "        loss.backward()   \n",
    "        \n",
    "        # 更新参数 \n",
    "        optimizer.step()\n",
    "        \n",
    "        # 打印log信息\n",
    "        # loss 是一个scalar,需要使用loss.item()来获取数值，不能使用loss[0]\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999: # 每2000个batch打印一下训练状态\n",
    "            print('[%d, %5d] loss: %.3f' \\\n",
    "                  % (epoch+1, i+1, running_loss / 2000)) #每2000个样本，计算平均loss值，打印\n",
    "            running_loss = 0.0\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "此处仅训练了2个epoch（遍历完一遍数据集称为一个epoch），来看看网络有没有效果。\n",
    "将测试图片输入到网络中，计算它的label，然后与实际的label进行比较。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000张测试集中的准确率为: 56 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0 # 预测正确的图片数\n",
    "total = 0 # 总共的图片数\n",
    "\n",
    "# 由于测试的时候不需要求导，可以暂时关闭autograd，提高速度，节约内存\n",
    "with t.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = t.max(outputs, 1) #??\n",
    "        total += labels.size(0) #??\n",
    "        correct += (predicted == labels).sum() #??\n",
    "\n",
    "print('10000张测试集中的准确率为: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在GPU训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型 从CPU转到GPU\n",
    "device = t.device(\"cuda:0\" if t.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net.to(device)\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "output = net(images)\n",
    "loss= criterion(output,labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "对PyTorch的基础介绍至此结束。总结一下，本节主要包含以下内容。\n",
    "\n",
    "  Tensor: 类似Numpy数组的数据结构，与Numpy接口类似，可方便地互相转换。\n",
    "  autograd: 为tensor提供自动求导功能。\n",
    "  nn: 专门为神经网络设计的接口，提供了很多有用的功能(神经网络层，损失函数，优化器等)。\n"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "Untitled.ipynb",
    "public": false
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

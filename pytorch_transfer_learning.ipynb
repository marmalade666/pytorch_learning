{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " https://www.pytorchtutorial.com/pytorch-transfer-learning/\n",
    "据库我们采用的是 Caltech 101 dataset，这个数据集包含 101 个图像分类，大多数分类只包含 50 张左右的图像，\\\n",
    "这对于神经网络来讲是远远不够的。\n",
    "\n",
    "那就用一个实现训练好的图像分类模型加迁移学习的方法，来实现在这个数据集上的训练。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "迁移学习（Transfer Learning）的基本概念就是当可用的数据集特别少时，从头开始训练一个神经网络往往不会得到很好的结果，于是就从一个预训练模型开始训练，让网络本身已经具备一定的训练基础，然后用小数据集进行微调，便可以得到一个不错的结果。\n",
    "通常加载预训练模型后，我们冻结模型的部分参数，一般只训练模型的最后几层，这样可以保留整个模型前面对物体特征提取的能力。预训练模型一定要与新的数据集有共同点，比如都是图像分类问题，这行才能有效地把预训练模型里的特征提取能力迁移到新的模型上。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "下面是迁移学习用于物体识别时的一般过程：\n",
    "\n",
    "加载预训练模型\n",
    "冻结模型前面部分的参数\n",
    "添加可训练的自定义的分类层，或使用原模型的分类层（如果可重用的话）\n",
    "在新数据集上训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像增广（Data augmentation）\n",
    "图像增广一般用来人工产生不同的图像，比如对图像进行旋转、翻转、随机裁剪、缩放等等。这里我们选择在训练阶段对输入进行增广，比如说我们训练了 20 个 epoch，那么每个 epoch 里网络看到的输入图像都会略微不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像预处理\n",
    "在 PyTorch 里，我们用 transforms 进行图像预处理。\n",
    "首先我们定义 training 和 validation 的预处理方式"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pytorch torchvision transform #对PIL.Image进行变换\n",
    "class torchvision.transforms.Compose(transforms) #将多个transform组合起来使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    " \n",
    "# Image transformations\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation图像增广\n",
    "    \\\\'train\\\\':\n",
    "    transforms.Compose([ #compose：将多个transform组合起来使用\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    \\\\'valid\\\\':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "接下来我们定义 dataset 和 DataLoader。\n",
    "用 datasets.ImageFolder 来定义 dataset 时 PyTorch 可以自动将图片与对应的文件夹分类对应起来，而且应用我们上面定义好的 transformers；\n",
    "然后 dataset 传入到 DataLoader 里，\n",
    "\n",
    "DataLoader 在每一个循环会自动生成 batchsize 大小的图像和 label。"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# ImageFolder\n",
    "一个通用的数据加载器，数据集中的数据以以下方式组织\n",
    "root/dog/xxx.png\n",
    "root/dog/xxy.png\n",
    "root/dog/xxz.png\n",
    "\n",
    "root/cat/123.png\n",
    "root/cat/nsdf3.png\n",
    "root/cat/asd932_.png\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dset.ImageFolder(root=\"root folder path\", [transform, target_transform])\n",
    "他有以下成员变量:\n",
    "\n",
    "self.classes - 用一个list保存 类名\n",
    "self.class_to_idx - 类名对应的 索引\n",
    "self.imgs - 保存(img-path, class) tuple的list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torchvision\n",
    "#pip install torchvision==0.1.8 #安装制定版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-97ee676edd2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Datasets from folders\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m data = {\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    " \n",
    "# Datasets from folders\n",
    "data = {\n",
    "    'train\\\\':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train\\\\']),\n",
    "    'valid\\\\':\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['valid\\\\']),\n",
    "}\n",
    " \n",
    "# Dataloader iterators, make sure to shuffle\n",
    "dataloaders = {\n",
    "    'train\\\\': DataLoader(data['train\\\\'], batch_size=batch_size, shuffle=True),\n",
    "    'val\\\\': DataLoader(data['valid\\\\'], batch_size=batch_size, shuffle=True)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-6-acca1da7a139>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-6-acca1da7a139>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    trainiter = iter(dataloaders[\\\\'train\\\\'])\u001b[0m\n\u001b[1;37m                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "#我们可以看一下 DataLoader 的输出：\n",
    "trainiter = iter(dataloaders['train\\\\'])\n",
    "features, labels = next(trainiter)\n",
    "features.shape, labels.shape\n",
    "(torch.Size([128, 3, 224, 224]), torch.Size([128]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mageNet 的预训练模型\n",
    "PyTorch 自带了很多 ImageNet 上的预训练模型，详细列表见这里。下表是各个模型的性能对比：\n",
    "本教程将选用 VGG-16 的预训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先加载预训练模型：\n",
    "from torchvision import models\n",
    "model = model.vgg16(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们只训练这个模型最后的全链接层，所以首先我们要冻结前面的参数：\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们的数据集只有 100 个分类，所以要在模型最后面加上几层使得模型的最终输出跟我们的类别数目一样：\n",
    "import torch.nn as nn\n",
    "# Add on classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),                   \n",
    "                      nn.LogSoftmax(dim=1))#？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这是什么格式的书写？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#我们来看一下整个模型：\n",
    "model.classifier\n",
    "Sequential(\n",
    "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
    "  (1): ReLU(inplace)\n",
    "  (2): Dropout(p=0.5)\n",
    "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
    "  (4): ReLU(inplace)\n",
    "  (5): Dropout(p=0.5)\n",
    "  (6): Sequential(\n",
    "    (0): Linear(in_features=4096, out_features=256, bias=True)\n",
    "    (1): ReLU()\n",
    "    (2): Dropout(p=0.4)\n",
    "    (3): Linear(in_features=256, out_features=100, bias=True)\n",
    "    (4): LogSoftmax()\n",
    "  )\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#统计模型参数数量\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print('{total_params:,} 参数总数.\\\\')\n",
    "\n",
    "total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('{total_trainable_params:,} 可训练参数总数.\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#损失函数和优化器\n",
    "from torch import optim\n",
    "# Loss and optimizer\n",
    "criteration = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下面是训练的伪代码，大家理解一下其中的思想：\n",
    "# 伪代码\n",
    "for epoch in range(n_epochs):\n",
    "  for data, targets in trainloader:\n",
    "    # Generate predictions\n",
    "    out = model(data)\n",
    "    # Calculate loss\n",
    "    loss = criterion(out, targets)\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    # Update model parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型训练好后，就可以做预测了：\n",
    "for data, targets in testloader:\n",
    "    log_ps = model(data)\n",
    "    # Convert to probabilities\n",
    "    ps = torch.exp(log_ps)\n",
    "ps.shape()\n",
    "(128, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#因为我们对所有分类都有输出概率，所以我们要找出概率最大的那个类别来作为最后的预测值\n",
    "# Find predictions and correct\n",
    "pred = torch.max(ps, dim=1)\n",
    "equals = pred == targets\n",
    "# Calculate accuracy\n",
    "accuracy = torch.mean(equals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

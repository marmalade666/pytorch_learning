{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nwordfreq https://pypi.org/project/wordfreq/\\nword_frequency(word, lang, wordlist='best', minimum=0.0)\\nfunction: tokenize()\\n>>> wordfreq.tokenize('l@s niñ@s', 'es')\\n['l@s', 'niñ@s'] #按空格分词成列表\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import wordfreq\n",
    "'''\n",
    "wordfreq https://pypi.org/project/wordfreq/\n",
    "word_frequency(word, lang, wordlist='best', minimum=0.0)\n",
    "function: tokenize()\n",
    ">>> wordfreq.tokenize('l@s niñ@s', 'es')\n",
    "['l@s', 'niñ@s'] #按空格分词成列表\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "token_id = 1 #token_id一般从1开始，最后再加一个unknown的id,0一般对应这句话为空的情况\n",
    "lengths = []\n",
    "\n",
    "with open('./data/test.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        tokens = wordfreq.tokenize(l.strip(), 'en')#1 text\n",
    "        lengths.append(len(tokens)) # store the length of all texts\n",
    "        for t in tokens:\n",
    "            if t not in vocab:\n",
    "                vocab[t] = token_id #construct vacab dict\n",
    "                token_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "共有 54 个词\n",
      "共有 4 条text\n",
      "vacab {'to': 1, 'the': 2, 'world': 3, 'you': 4, 'may': 5, 'be': 6, 'one': 7, 'person': 8, 'but': 9, 'no': 10, 'man': 11, 'or': 12, 'woman': 13, 'is': 14, 'worth': 15, 'your': 16, 'tears': 17, 'and': 18, 'who': 19, 'won': 20, '鈥檛': 21, 'make': 22, 'cry': 23, 'never': 24, 'frown': 25, 'even': 26, 'when': 27, 'are': 28, 'sad': 29, 'because': 30, 'know': 31, 'falling': 32, 'in': 33, 'love': 34, 'with': 35, 'smile': 36, 'we': 37, 'met': 38, 'at': 39, 'wrong': 40, 'time': 41, 'separated': 42, 'right': 43, 'most': 44, 'urgent': 45, 'take': 46, 'beautiful': 47, 'scenery': 48, 'deepest': 49, 'wound': 50, 'was': 51, 'real': 52, 'emotions': 53}\n"
     ]
    }
   ],
   "source": [
    "print('共有 %d 个词'%token_id)\n",
    "print('共有 %d 条text'%len(lengths))\n",
    "print('vacab', vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(lengths), max(lengths))) #initialize x \n",
    "l_no = 0\n",
    "with open('./data/test.txt', 'r') as f:\n",
    "    for l in f:\n",
    "        tokens = wordfreq.tokenize(l.strip(), 'en')\n",
    "        for i in range(len(tokens)):\n",
    "            x[l_no, i] = vocab[tokens[i]] #construct x, 总觉得这里reread file 有点多余，也许可以优化\n",
    "        l_no += 1 # text idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.,  1.,  7.,  8.,  4.,\n",
       "         5.,  6.,  2.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.],\n",
       "       [10., 11., 12., 13., 14., 15., 16., 17., 18.,  2.,  7., 19., 14.,\n",
       "        20., 21., 22.,  4., 23.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.],\n",
       "       [24., 25., 26., 27.,  4., 28., 29., 30.,  4., 24., 31., 19., 14.,\n",
       "        32., 33., 34., 35., 16., 36.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.],\n",
       "       [37., 38., 39.,  2., 40., 41.,  9., 42., 39.,  2., 43., 41.,  2.,\n",
       "        44., 45., 14.,  1., 46.,  2., 44., 47., 48.,  2., 49., 50., 51.,\n",
       "         2., 44., 52., 53.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x#除去最长的那个text,其他不够长的text一律补0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntorch.sort(input, dim=None, descending=False, out=None)\\ninput:输入张量\\ndim:指定维度，默认为输入的最后一个维度\\ndescending:若为True,则为降序排列\\n返回元组(sorted_tensor,sorted_indices),indices是index的复数形式,sorted_indices是排序后的原始输入的下标\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x=torch.Tensor(x)\n",
    "x = Variable(x) #transform x to torch.autograd.Variable\n",
    "'''\n",
    "torch.autograd.Variable:https://pytorch-cn.readthedocs.io/zh/latest/package_references/torch-autograd/\n",
    "\n",
    "'''\n",
    "lengths = torch.Tensor(lengths) # transform lengths to torch.Tensor\n",
    "_, idx_sort = torch.sort(lengths, dim=0, descending=True)\n",
    "_, idx_unsort = torch.sort(idx_sort, dim=0)#idx_unsort的作用在于将batch中的序列调整为原来的顺序。\n",
    "'''\n",
    "torch.sort(input, dim=None, descending=False, out=None)\n",
    "input:输入张量\n",
    "dim:指定维度，默认为输入的最后一个维度\n",
    "descending:若为True,则为降序排列\n",
    "返回元组(sorted_tensor,sorted_indices),indices是index的复数形式,sorted_indices是排序后的原始输入的下标\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([17., 18., 19., 30.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 1, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_unsort#??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x排序之前： tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.,  1.,  7.,  8.,  4.,  5.,\n",
      "          6.,  2.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.],\n",
      "        [10., 11., 12., 13., 14., 15., 16., 17., 18.,  2.,  7., 19., 14., 20.,\n",
      "         21., 22.,  4., 23.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.],\n",
      "        [24., 25., 26., 27.,  4., 28., 29., 30.,  4., 24., 31., 19., 14., 32.,\n",
      "         33., 34., 35., 16., 36.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.],\n",
      "        [37., 38., 39.,  2., 40., 41.,  9., 42., 39.,  2., 43., 41.,  2., 44.,\n",
      "         45., 14.,  1., 46.,  2., 44., 47., 48.,  2., 49., 50., 51.,  2., 44.,\n",
      "         52., 53.]])\n",
      "x排序之后： tensor([[37., 38., 39.,  2., 40., 41.,  9., 42., 39.,  2., 43., 41.,  2., 44.,\n",
      "         45., 14.,  1., 46.,  2., 44., 47., 48.,  2., 49., 50., 51.,  2., 44.,\n",
      "         52., 53.],\n",
      "        [24., 25., 26., 27.,  4., 28., 29., 30.,  4., 24., 31., 19., 14., 32.,\n",
      "         33., 34., 35., 16., 36.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.],\n",
      "        [10., 11., 12., 13., 14., 15., 16., 17., 18.,  2.,  7., 19., 14., 20.,\n",
      "         21., 22.,  4., 23.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.],\n",
      "        [ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.,  1.,  7.,  8.,  4.,  5.,\n",
      "          6.,  2.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "          0.,  0.]])\n",
      "lengths排序之前： tensor([17., 18., 19., 30.])\n",
      "lengths排序之后： [tensor(30.), tensor(19.), tensor(18.), tensor(17.)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npack_padded_sequence函数的参数:\\ninput:x为已根据长度 从大到小 排好序\\nlengths:需要 从大到小 排序\\nbatch_first:如果为true，则x的第一维为batch_size，第二维为seq_length，否则相反。\\n'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#将x 和lengths 都从大到小 排序\n",
    "print('x排序之前：',x)\n",
    "#pack_padded_sequence\n",
    "x = x.index_select(0, idx_sort)\n",
    "print('x排序之后：',x)\n",
    "#index_select(x, 1, indices) #索引查找\n",
    "#1 代表维度1，indices筛选的索引序号\n",
    "print('lengths排序之前：',lengths)\n",
    "lengths = list(lengths[idx_sort])\n",
    "print('lengths排序之后：',lengths)\n",
    "\n",
    "\n",
    "x_packed = nn.utils.rnn.pack_padded_sequence(input=x, lengths=lengths, batch_first=True)\n",
    "'''\n",
    "pack_padded_sequence函数的参数:\n",
    "input:x为已根据长度 从大到小 排好序\n",
    "lengths:需要 从大到小 排序\n",
    "batch_first:如果为true，则x的第一维为batch_size，第二维为seq_length，否则相反。\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([37., 24., 10.,  1., 38., 25., 11.,  2., 39., 26., 12.,  3.,  2., 27.,\n",
       "        13.,  4., 40.,  4., 14.,  5., 41., 28., 15.,  6.,  9., 29., 16.,  7.,\n",
       "        42., 30., 17.,  8., 39.,  4., 18.,  9.,  2., 24.,  2.,  1., 43., 31.,\n",
       "         7.,  7., 41., 19., 19.,  8.,  2., 14., 14.,  4., 44., 32., 20.,  5.,\n",
       "        45., 33., 21.,  6., 14., 34., 22.,  2.,  1., 35.,  4.,  3., 46., 16.,\n",
       "        23.,  2., 36., 44., 47., 48.,  2., 49., 50., 51.,  2., 44., 52., 53.]), batch_sizes=tensor([4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 2, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed #我觉得应该是矩阵压缩，但我看不懂这个压缩后的矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad_packed_sequence\n",
    "x_padded = nn.utils.rnn.pad_packed_sequence(x_packed, batch_first=True)\n",
    "output = x_padded[0].index_select(0, idx_unsort)#把x_padded还原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9.,  1.,  7.,  8.,  4.,  5.,\n",
       "          6.,  2.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.],\n",
       "        [10., 11., 12., 13., 14., 15., 16., 17., 18.,  2.,  7., 19., 14., 20.,\n",
       "         21., 22.,  4., 23.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.],\n",
       "        [24., 25., 26., 27.,  4., 28., 29., 30.,  4., 24., 31., 19., 14., 32.,\n",
       "         33., 34., 35., 16., 36.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "          0.,  0.],\n",
       "        [37., 38., 39.,  2., 40., 41.,  9., 42., 39.,  2., 43., 41.,  2., 44.,\n",
       "         45., 14.,  1., 46.,  2., 44., 47., 48.,  2., 49., 50., 51.,  2., 44.,\n",
       "         52., 53.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
